{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/OpenPipe/ART/blob/main/examples/mcp-rl/mcp-rl-alphavantage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caZYLROd8xnV"
   },
   "source": [
    "To train a model for your custom task, click _Runtime_ and press _Run all_. Make sure you've enabled a free Tesla T4 GPU!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n",
    "\n",
    "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
    "\n",
    "**MCPâ€¢RL: Tool-driven agent training**\n",
    "\n",
    "This notebook shows how to train a Qwen 2.5 7B model to automatically optimize against any MCP server. Simply define the server's tools and resources and the notebook below will:\n",
    "\n",
    "1. Query the server's tools and resources\n",
    "2. Generate diverse input examples for your task\n",
    "3. Train the model using RULER's automatic evaluation\n",
    "4. Test the trained model on new inputs against the server\n",
    "\n",
    "RULER learns what makes a good output purely from the MCP server's tools and resources - no expected outputs required!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "OsrwCDQ5cviC"
   },
   "outputs": [],
   "source": [
    "# @title ðŸ’¿ Installation\n",
    "\n",
    "!uv pip install -q openpipe-art==0.3.11.post2 langchain-core tenacity \"mcp>=1.11.0\" \"gql<4\" fastmcp --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8b8kgQ69ZDM"
   },
   "source": [
    "<a name=\"Configuration\"></a>\n",
    "\n",
    "### ðŸŽ¯ Configuration - Edit These Settings\n",
    "\n",
    "Add an OpenRouter key and customize your training by modifying the values below.\n",
    "\n",
    "By default your model will be trained to retrieve and analyze stock and crypto market data from the Alphavantage MCP server. To teach your model to use another MCP server, configure it to run in the [MCP server](#mcp) cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "so6r1_OG9en3"
   },
   "outputs": [],
   "source": [
    "# Required - Used for generating training inputs and RULER evaluation\n",
    "OPENROUTER_API_KEY = \"\"\n",
    "\n",
    "# Optional - Enables metric logging\n",
    "WANDB_API_KEY = \"\"\n",
    "\n",
    "# Shared key for the demo - DO NOT USE IN PRODUCTION, AND EXPECT RATE LIMITS\n",
    "ALPHAVANTAGE_API_KEY = \"HR32X84C3B4HJ93C\"\n",
    "\n",
    "# Choose the base model to train\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"  # Options: \"Qwen/Qwen2.5-3B-Instruct\", \"Qwen/Qwen2.5-7B-Instruct\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "I_AFDSOv_LrB"
   },
   "outputs": [],
   "source": [
    "# @title Advanced Settings\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"mcp-7b-alphavantage\"  # Name for your trained model\n",
    "PROJECT_NAME = \"mcp-rl\"  # Project name for tracking\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    \"num_training_inputs\": 16,  # Number of training inputs to generate\n",
    "    \"groups_per_step\": 2,  # Inputs to process per training step\n",
    "    \"num_epochs\": 3,  # Number of times through all data\n",
    "    \"rollouts_per_group\": 3,  # Different responses per input (for RULER comparison)\n",
    "    \"learning_rate\": 1e-5,  # Learning rate\n",
    "    \"max_training_steps\": None,  # Maximum training steps (set to None for no limit)\n",
    "}\n",
    "\n",
    "MAX_TURNS = 10  # Maximum number of turns for the model to generate during one rollout\n",
    "\n",
    "NUM_TEST_INPUTS = 8  # Number of test inputs to generate\n",
    "RULER_MODEL = \"openrouter/openai/o4-mini\"  # Model for RULER evaluation\n",
    "INPUT_GENERATION_MODEL = \"openai/o4-mini\"\n",
    "\n",
    "# GPU configuration (for T4 â€”Â keep these as-is unless you have a reason to change them)\n",
    "MAX_SEQ_LENGTH = 4096  # Maximum sequence length\n",
    "GPU_MEMORY_UTILIZATION = 0.7  # GPU memory usage (0.0-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title MCP server\n",
    "\n",
    "import asyncio\n",
    "from typing import Any, Dict\n",
    "import aiohttp\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type,\n",
    ")\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Required for Alphavantage demo\n",
    "if ALPHAVANTAGE_API_KEY:\n",
    "    os.environ[\"ALPHAVANTAGE_API_KEY\"] = ALPHAVANTAGE_API_KEY\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"ALPHAVANTAGE_API_KEY is required for the Alphavantage demo.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AlphaVantageClient:\n",
    "    \"\"\"Client for interacting with Alpha Vantage API\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "    async def fetch_data(self, function: str, **params) -> Dict[str, Any]:\n",
    "        \"\"\"Fetch data from Alpha Vantage API\"\"\"\n",
    "        query_params = {\n",
    "            \"function\": function,\n",
    "            \"apikey\": self.api_key,\n",
    "            \"datatype\": \"json\",\n",
    "            **params,\n",
    "        }\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(self.base_url, params=query_params) as response:\n",
    "                if response.status != 200:\n",
    "                    raise Exception(f\"API request failed: {response.status}\")\n",
    "\n",
    "                data = await response.json()\n",
    "\n",
    "                if \"Error Message\" in data:\n",
    "                    raise Exception(f\"Alpha Vantage API Error: {data['Error Message']}\")\n",
    "\n",
    "                if (\n",
    "                    \"Thank you for using Alpha Vantage! Please contact premium@alphavantage.co if you are targeting a higher API call volume.\"\n",
    "                    in data\n",
    "                ):\n",
    "                    raise Exception(\n",
    "                        \"Alpha Vantage API Error: Thank you for using Alpha Vantage! Please contact premium@alphavantage.co if you are targeting a higher API call volume.\"\n",
    "                    )\n",
    "\n",
    "                return data\n",
    "\n",
    "\n",
    "def _format_json(data: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format JSON data for display\"\"\"\n",
    "    import json\n",
    "    return json.dumps(data, indent=2)\n",
    "\n",
    "\n",
    "# Initialize FastMCP server\n",
    "mcp = FastMCP(\"mcp-alphavantage\")\n",
    "client = AlphaVantageClient(os.getenv(\"ALPHAVANTAGE_API_KEY\"))\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def get_stock_quote(symbol: str) -> str:\n",
    "    \"\"\"Get real-time stock quote for a symbol\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., AAPL, MSFT)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\"GLOBAL_QUOTE\", symbol=symbol)\n",
    "    return f\"Stock Quote for {symbol}:\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def get_time_series_daily(symbol: str, outputsize: str = \"compact\") -> str:\n",
    "    \"\"\"Get daily time series data for a stock\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., AAPL, MSFT)\n",
    "        outputsize: Output size: compact (latest 100 data points)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\n",
    "        \"TIME_SERIES_DAILY\",\n",
    "        symbol=symbol,\n",
    "        outputsize=outputsize,\n",
    "    )\n",
    "    return f\"Daily Time Series for {symbol}:\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def search_symbol(keywords: str) -> str:\n",
    "    \"\"\"Search for stock symbols by keywords\n",
    "    \n",
    "    Args:\n",
    "        keywords: Keywords to search for (e.g., company name)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\"SYMBOL_SEARCH\", keywords=keywords)\n",
    "    return f\"Symbol Search Results for '{keywords}':\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def get_company_overview(symbol: str) -> str:\n",
    "    \"\"\"Get fundamental data and company overview\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., AAPL, MSFT)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\"OVERVIEW\", symbol=symbol)\n",
    "    return f\"Company Overview for {symbol}:\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def get_sma(\n",
    "    symbol: str, \n",
    "    interval: str = \"daily\", \n",
    "    time_period: int = 30, \n",
    "    series_type: str = \"close\"\n",
    ") -> str:\n",
    "    \"\"\"Get Simple Moving Average (SMA) technical indicator\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., AAPL, MSFT)\n",
    "        interval: Time interval (1min, 5min, 15min, 30min, 60min, daily, weekly, monthly)\n",
    "        time_period: Number of data points for SMA calculation\n",
    "        series_type: Price type to use for calculation (close, open, high, low)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\n",
    "        \"SMA\",\n",
    "        symbol=symbol,\n",
    "        interval=interval,\n",
    "        time_period=time_period,\n",
    "        series_type=series_type,\n",
    "    )\n",
    "    tech_analysis_key = \"Technical Analysis: SMA\"\n",
    "    # Alpha Vantage returns a dict keyed by timestamp; convert to list to slice\n",
    "    data[tech_analysis_key] = dict(\n",
    "        list(data[tech_analysis_key].items())[:time_period]\n",
    "    )\n",
    "    return f\"SMA for {symbol}:\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "@mcp.tool\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=30),\n",
    "    retry=retry_if_exception_type(\n",
    "        (aiohttp.ClientError, asyncio.TimeoutError, Exception)\n",
    "    ),\n",
    ")\n",
    "async def get_rsi(\n",
    "    symbol: str, \n",
    "    interval: str = \"daily\", \n",
    "    time_period: int = 14, \n",
    "    series_type: str = \"close\"\n",
    ") -> str:\n",
    "    \"\"\"Get Relative Strength Index (RSI) technical indicator\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock symbol (e.g., AAPL, MSFT)\n",
    "        interval: Time interval (daily, weekly, monthly)\n",
    "        time_period: Number of data points for RSI calculation\n",
    "        series_type: Price type to use for calculation (close, open, high, low)\n",
    "    \"\"\"\n",
    "    data = await client.fetch_data(\n",
    "        \"RSI\",\n",
    "        symbol=symbol,\n",
    "        interval=interval,\n",
    "        time_period=time_period,\n",
    "        series_type=series_type,\n",
    "    )\n",
    "    tech_analysis_key = \"Technical Analysis: RSI\"\n",
    "    # Alpha Vantage returns a dict keyed by timestamp; convert to list to slice\n",
    "    data[tech_analysis_key] = dict(\n",
    "        list(data[tech_analysis_key].items())[:time_period]\n",
    "    )\n",
    "    return f\"RSI for {symbol}:\\n{_format_json(data)}\"\n",
    "\n",
    "\n",
    "# For in-memory usage, we don't need server_params anymore\n",
    "# The FastMCP server is now available as the 'mcp' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"mcp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools_result [Tool(name='get_stock_quote', title=None, description='Get real-time stock quote for a symbol\\n\\nArgs:\\n    symbol: Stock symbol (e.g., AAPL, MSFT)', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}}, 'required': ['symbol'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='get_time_series_daily', title=None, description='Get daily time series data for a stock\\n\\nArgs:\\n    symbol: Stock symbol (e.g., AAPL, MSFT)\\n    outputsize: Output size: compact (latest 100 data points)', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}, 'outputsize': {'default': 'compact', 'title': 'Outputsize', 'type': 'string'}}, 'required': ['symbol'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='search_symbol', title=None, description='Search for stock symbols by keywords\\n\\nArgs:\\n    keywords: Keywords to search for (e.g., company name)', inputSchema={'properties': {'keywords': {'title': 'Keywords', 'type': 'string'}}, 'required': ['keywords'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='get_company_overview', title=None, description='Get fundamental data and company overview\\n\\nArgs:\\n    symbol: Stock symbol (e.g., AAPL, MSFT)', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}}, 'required': ['symbol'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='get_sma', title=None, description='Get Simple Moving Average (SMA) technical indicator\\n\\nArgs:\\n    symbol: Stock symbol (e.g., AAPL, MSFT)\\n    interval: Time interval (1min, 5min, 15min, 30min, 60min, daily, weekly, monthly)\\n    time_period: Number of data points for SMA calculation\\n    series_type: Price type to use for calculation (close, open, high, low)', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}, 'interval': {'default': 'daily', 'title': 'Interval', 'type': 'string'}, 'time_period': {'default': 30, 'title': 'Time Period', 'type': 'integer'}, 'series_type': {'default': 'close', 'title': 'Series Type', 'type': 'string'}}, 'required': ['symbol'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='get_rsi', title=None, description='Get Relative Strength Index (RSI) technical indicator\\n\\nArgs:\\n    symbol: Stock symbol (e.g., AAPL, MSFT)\\n    interval: Time interval (daily, weekly, monthly)\\n    time_period: Number of data points for RSI calculation\\n    series_type: Price type to use for calculation (close, open, high, low)', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}, 'interval': {'default': 'daily', 'title': 'Interval', 'type': 'string'}, 'time_period': {'default': 14, 'title': 'Time Period', 'type': 'integer'}, 'series_type': {'default': 'close', 'title': 'Series Type', 'type': 'string'}}, 'required': ['symbol'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}})]\n"
     ]
    }
   ],
   "source": [
    "# @title Let's generate our train and validation scenarios!\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "from fastmcp import Client\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "async def generate_scenarios(\n",
    "    mcp_server: FastMCP,\n",
    "    num_scenarios: int = 24,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    # Connect to MCP server using in-memory transport\n",
    "    async with Client(mcp_server) as client:\n",
    "        # Get available tools\n",
    "        tools_result = await client.list_tools()\n",
    "        tools_info = []\n",
    "        for tool in tools_result:\n",
    "            tool_info = {\n",
    "                \"name\": tool.name,\n",
    "                \"description\": tool.description,\n",
    "                \"parameters\": tool.inputSchema,\n",
    "            }\n",
    "            tools_info.append(tool_info)\n",
    "\n",
    "        # Get available resources\n",
    "        try:\n",
    "            resources_result = await client.list_resources()\n",
    "            resources_info = []\n",
    "            for resource in resources_result.resources:\n",
    "                resource_info = {\n",
    "                    \"uri\": str(resource.uri),\n",
    "                    \"name\": resource.name,\n",
    "                    \"description\": resource.description,\n",
    "                    \"mimeType\": resource.mimeType,\n",
    "                }\n",
    "                resources_info.append(resource_info)\n",
    "        except Exception:\n",
    "            # Some servers might not have resources\n",
    "            resources_info = []\n",
    "\n",
    "    # Prepare the prompt for o3\n",
    "    tools_description = json.dumps(tools_info, indent=2)\n",
    "    resources_description = (\n",
    "        json.dumps(resources_info, indent=2)\n",
    "        if resources_info\n",
    "        else \"No resources available\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"You are an expert at creating realistic scenarios for testing AI agents that interact with MCP (Model Context Protocol) servers.\n",
    "\n",
    "Given the following available tools and resources from an MCP server, generate {num_scenarios} diverse, realistic scenarios that a user might want to accomplish using these tools.\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "{tools_description}\n",
    "\n",
    "AVAILABLE RESOURCES:\n",
    "{resources_description}\n",
    "\n",
    "Requirements for scenarios:\n",
    "1. Each scenario should be a task that can be accomplished using the available tools\n",
    "2. Scenarios should vary in complexity - some simple (1-2 tool calls), some complex (multiple tool calls)\n",
    "3. Scenarios should cover different use cases and tool combinations (though the task should not specify which tools to use)\n",
    "4. Each scenario should be realistic - something a real user might actually want to do\n",
    "5. Assign a difficulty rating from 1 (easy, single tool call) to 5 (hard, complex multi-step analysis)\n",
    "6. The task should always include generating a summary of the work done and a thorough analysis and report of the results\n",
    "\n",
    "You must respond with a JSON object containing a \"scenarios\" array of exactly {num_scenarios} objects. Each object must have:\n",
    "- \"task\": string describing the scenario\n",
    "- \"difficulty\": integer from 1-5 representing complexity\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"scenarios\": [\n",
    "    {{\"task\": \"Get the current stock price for Apple (AAPL)\", \"difficulty\": 1}},\n",
    "    {{\"task\": \"Compare the 30-day SMA with current price for Tesla and determine if it's above or below the moving average and generate a thorough analysis and report\", \"difficulty\": 2}}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "\n",
    "    # Call OpenAI's model with structured JSON output\n",
    "    client_openai = openai.OpenAI(\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "    )\n",
    "\n",
    "    # Define the JSON schema for the response\n",
    "    response_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"scenarios\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task\": {\"type\": \"string\"},\n",
    "                        \"difficulty\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 5},\n",
    "                    },\n",
    "                    \"required\": [\"task\", \"difficulty\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "                \"minItems\": num_scenarios,\n",
    "                \"maxItems\": num_scenarios,\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"scenarios\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "\n",
    "    response = client_openai.chat.completions.create(\n",
    "        model=INPUT_GENERATION_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_completion_tokens=4000,\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\": \"scenario_list\", \"schema\": response_schema},\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Parse the JSON response\n",
    "    content = response.choices[0].message.content\n",
    "    result = json.loads(content)\n",
    "\n",
    "    # Extract scenarios from the response\n",
    "    if \"scenarios\" in result:\n",
    "        scenarios = result[\"scenarios\"]\n",
    "    else:\n",
    "        # If the response is just an array\n",
    "        scenarios = result if isinstance(result, list) else list(result.values())[0]\n",
    "\n",
    "    # Validate we got exactly the right number\n",
    "    if len(scenarios) != num_scenarios:\n",
    "        raise ValueError(f\"Expected {num_scenarios} scenarios, got {len(scenarios)}\")\n",
    "\n",
    "    return scenarios\n",
    "\n",
    "\n",
    "num_scenarios = TRAINING_CONFIG[\"num_training_inputs\"] + NUM_TEST_INPUTS\n",
    "for _ in range(10):\n",
    "    scenarios = await generate_scenarios(\n",
    "        mcp,  # Use the FastMCP server directly\n",
    "        num_scenarios=num_scenarios,\n",
    "    )\n",
    "\n",
    "    if len(scenarios) == num_scenarios:\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"\\nGenerated {len(scenarios)} scenarios:\")\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"{i}. Task: {scenario['task']}\")\n",
    "    print(f\"   Difficulty: {scenario['difficulty']}/5\")\n",
    "\n",
    "# Shuffle scenarios randomly\n",
    "random.shuffle(scenarios)\n",
    "\n",
    "raw_train_scenarios = scenarios[:TRAINING_CONFIG[\"num_training_inputs\"]]\n",
    "raw_val_scenarios = scenarios[TRAINING_CONFIG[\"num_training_inputs\"]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:2154\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2154\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2155\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:2184\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:2182\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:73\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     65\u001b[0m     ALL_PARALLEL_STYLES,\n\u001b[1;32m     66\u001b[0m     _get_parameter_tp_plan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     verify_tp_plan,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     Conv1D,\n\u001b[1;32m     76\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     prune_linear_layer,\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/loss/loss_utils.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_d_fine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DFineForObjectDetectionLoss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/loss/loss_d_fine.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_vision_available\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     box_iou,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_rt_detr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDetrHungarianMatcher, RTDetrLoss\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/loss/loss_for_object_detection.py:32\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdice_loss\u001b[39m(inputs, targets, num_boxes):\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/image_transforms.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ChannelDimension,\n\u001b[1;32m     24\u001b[0m     ImageInput,\n\u001b[1;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[1;32m     26\u001b[0m     get_image_size,\n\u001b[1;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/image_utils.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[1;32m     61\u001b[0m     pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST_EXACT,\n\u001b[1;32m     63\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m         PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[1;32m     68\u001b[0m     }\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/torchvision/datasets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optical_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stereo_matching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     CarlaStereo,\n\u001b[1;32m      4\u001b[0m     CREStereo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     SintelStereo,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/torchvision/datasets/_optical_flow.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decode_png, read_file\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionDataset\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/torchvision/datasets/utils.py:4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhashlib\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/lzma.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mart\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterate_dataset\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalBackend\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ruler_score_group\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/art/local/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalBackend\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocalBackend\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/art/local/backend.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Backend\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model, TrainableModel\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelService\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrajectories\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trajectory, TrajectoryGroup\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Message, TrainConfig\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/art/local/service.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_step, get_last_checkpoint_dir\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DiskPackedTensors, packed_tensors_from_dir, PackedTensors\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvllm_lora_request\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoRARequest  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/art/local/train.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRPOTrainer\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/peft/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present the HuggingFace Inc. team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.17.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[1;32m     19\u001b[0m     AutoPeftModel,\n\u001b[1;32m     20\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     21\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     22\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     23\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig, PromptLearningConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m     30\u001b[0m     PEFT_TYPE_TO_MIXED_MODEL_MAPPING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     inject_adapter_in_model,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/peft/auto.py:31\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoModel,\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     AutoTokenizer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     PeftModel,\n\u001b[1;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TOKENIZER_CONFIG_NAME\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/peft/config.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin, http_user_agent\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_NAME, PeftType, TaskType\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# we expect at least these keys to be present in a PEFT adapter_config.json\u001b[39;00m\n\u001b[1;32m     28\u001b[0m MIN_EXPECTED_CONFIG_KEYS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft_type\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/peft/utils/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_cache_to_layer_device_map\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloftq_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_lora_weights_loftq\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     19\u001b[0m     INCLUDE_LINEAR_LAYERS_SHORTHAND,\n\u001b[1;32m     20\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[1;32m     21\u001b[0m     TRANSFORMERS_MODELS_TO_ADALORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     22\u001b[0m     TRANSFORMERS_MODELS_TO_C3A_TARGET_MODULES_MAPPING,\n\u001b[1;32m     23\u001b[0m     TRANSFORMERS_MODELS_TO_FOURIERFT_TARGET_MODULES_MAPPING,\n\u001b[1;32m     24\u001b[0m     TRANSFORMERS_MODELS_TO_IA3_FEEDFORWARD_MODULES_MAPPING,\n\u001b[1;32m     25\u001b[0m     TRANSFORMERS_MODELS_TO_IA3_TARGET_MODULES_MAPPING,\n\u001b[1;32m     26\u001b[0m     TRANSFORMERS_MODELS_TO_LNTUNING_TARGET_MODULES_MAPPING,\n\u001b[1;32m     27\u001b[0m     TRANSFORMERS_MODELS_TO_LOHA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     28\u001b[0m     TRANSFORMERS_MODELS_TO_LOKR_TARGET_MODULES_MAPPING,\n\u001b[1;32m     29\u001b[0m     TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     30\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m     31\u001b[0m     TRANSFORMERS_MODELS_TO_RANDLORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     32\u001b[0m     TRANSFORMERS_MODELS_TO_SHIRA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     33\u001b[0m     TRANSFORMERS_MODELS_TO_VBLORA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     34\u001b[0m     TRANSFORMERS_MODELS_TO_VERA_TARGET_MODULES_MAPPING,\n\u001b[1;32m     35\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     36\u001b[0m     AuxiliaryTrainingWrapper,\n\u001b[1;32m     37\u001b[0m     ModulesToSaveWrapper,\n\u001b[1;32m     38\u001b[0m     _freeze_adapter,\n\u001b[1;32m     39\u001b[0m     _get_batch_size,\n\u001b[1;32m     40\u001b[0m     _get_input_embeddings_name,\n\u001b[1;32m     41\u001b[0m     _get_submodules,\n\u001b[1;32m     42\u001b[0m     _is_valid_match,\n\u001b[1;32m     43\u001b[0m     _prepare_prompt_learning_config,\n\u001b[1;32m     44\u001b[0m     _set_adapter,\n\u001b[1;32m     45\u001b[0m     _set_trainable,\n\u001b[1;32m     46\u001b[0m     bloom_model_postprocess_past_key_value,\n\u001b[1;32m     47\u001b[0m     cast_mixed_precision_params,\n\u001b[1;32m     48\u001b[0m     get_auto_gptq_quant_linear,\n\u001b[1;32m     49\u001b[0m     get_gptqmodel_quant_linear,\n\u001b[1;32m     50\u001b[0m     get_quantization_config,\n\u001b[1;32m     51\u001b[0m     id_tensor_storage,\n\u001b[1;32m     52\u001b[0m     infer_device,\n\u001b[1;32m     53\u001b[0m     prepare_model_for_kbit_training,\n\u001b[1;32m     54\u001b[0m     set_additional_trainable_modules,\n\u001b[1;32m     55\u001b[0m     shift_tokens_right,\n\u001b[1;32m     56\u001b[0m     transpose,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftType, TaskType, register_peft_method\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave_and_load\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_peft_model_state_dict, load_peft_weights, set_peft_model_state_dict\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/peft/utils/other.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m storage_ptr, storage_size\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_auto_gptq_available, is_gptqmodel_available, is_torch_tpu_available\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     41\u001b[0m     EMBEDDING_LAYER_NAMES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     starcoder_model_postprocess_past_key_value,\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m~/playground/openpipe/agent-reinforcement-training/examples/mcp-rl/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:2157\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2155\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2156\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2157\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m   2158\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Are this object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms requirements defined correctly?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2159\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m   2162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'PreTrainedModel'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "# @title Run this cell to train your model!\n",
    "\n",
    "import art\n",
    "from art.utils import iterate_dataset\n",
    "from art.local import LocalBackend\n",
    "from art.ruler import ruler_score_group\n",
    "from dataclasses import dataclass\n",
    "import weave\n",
    "from fastmcp import Client\n",
    "import mcp.types as types\n",
    "from openai import AsyncOpenAI\n",
    "import json\n",
    "\n",
    "# Required\n",
    "if OPENROUTER_API_KEY:\n",
    "    os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"OPENROUTER_API_KEY is required for data generation and RULER evaluation.\"\n",
    "    )\n",
    "\n",
    "# Optional\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    weave.init(PROJECT_NAME)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY is not set. We'll skip logging metrics to Weights & Biases.\")\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model\n",
    "model = art.TrainableModel(\n",
    "    name=MODEL_NAME,\n",
    "    project=PROJECT_NAME,\n",
    "    base_model=BASE_MODEL,\n",
    ")\n",
    "\n",
    "# To run on a T4, we need to override some config defaults.\n",
    "model._internal_config = art.dev.InternalModelConfig(\n",
    "    init_args=art.dev.InitArgs(\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "    ),\n",
    "    engine_args=art.dev.EngineArgs(\n",
    "        enforce_eager=True,\n",
    "        gpu_memory_utilization=GPU_MEMORY_UTILIZATION,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "backend = LocalBackend(\n",
    "    in_process=True,\n",
    "    path=\"./.art\",\n",
    ")\n",
    "\n",
    "# Register the model with the local Backend\n",
    "await model.register(backend)\n",
    "\n",
    "print(\"Model created!\")\n",
    "print(\"Base model:\", BASE_MODEL)\n",
    "print(\"Model name:\", MODEL_NAME)\n",
    "print(\"Project name:\", PROJECT_NAME)\n",
    "\n",
    "# =============== Rollout function code ===============\n",
    "\n",
    "def get_content_text(result) -> str:\n",
    "    # Extract text content from tool call result\n",
    "    if isinstance(result, str):\n",
    "        return result\n",
    "    elif hasattr(result, \"content\") and result.content:\n",
    "        if isinstance(result.content, list):\n",
    "            # Handle list of content items\n",
    "            content_text = \"\"\n",
    "            for item in result.content:\n",
    "                if isinstance(item, types.TextContent):\n",
    "                    content_text += item.text\n",
    "                else:\n",
    "                    content_text += str(item)\n",
    "        elif isinstance(result.content[0], types.TextContent):\n",
    "            content_text = result.content[0].text\n",
    "        else:\n",
    "            content_text = str(result.content)\n",
    "    else:\n",
    "        content_text = str(result)\n",
    "\n",
    "    return content_text\n",
    "\n",
    "@dataclass\n",
    "class McpScenario:\n",
    "    \"\"\"A scenario for MCP agent evaluation.\"\"\"\n",
    "\n",
    "    task_description: str\n",
    "    mcp_server: FastMCP\n",
    "    max_turns: int = 10\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "async def rollout(\n",
    "    model: art.Model,\n",
    "    scenario: McpScenario,\n",
    "    debug: bool = False,\n",
    ") -> art.Trajectory:\n",
    "    \"\"\"Run an MCP agent rollout with FastMCP server.\n",
    "\n",
    "    Args:\n",
    "        model: The ART model to use for the agent\n",
    "        scenario: The MCP scenario to run (must include mcp_server)\n",
    "\n",
    "    Returns:\n",
    "        Trajectory containing the results of the rollout\n",
    "    \"\"\"\n",
    "    traj = art.Trajectory(\n",
    "        messages_and_choices=[],\n",
    "        reward=0,\n",
    "        metadata={\"task\": scenario.task_description},\n",
    "        metrics={\n",
    "            \"task_completed\": False,\n",
    "            \"success\": False,\n",
    "            \"ran_out_of_turns\": False,\n",
    "        },\n",
    "        scenario=scenario,\n",
    "    )\n",
    "\n",
    "    # Initialize system prompt\n",
    "    system_prompt = f\"\"\"You are an MCP (Model Context Protocol) agent.\\n\\nYou have access to MCP tools through the server. Use them to complete your task.\\n\\nWhen you believe you have completed the task, call the 'complete_task' function with a summary of what you accomplished. You have a total of {scenario.max_turns} turns to complete the task. Only use tool calls, do not write any content. After you have completed the task, call the 'complete_task' function with a summary of what you accomplished. Call complete_task by itself, not in conjunction with any other tools.\"\"\"\n",
    "\n",
    "    # Connect to FastMCP server using in-memory transport\n",
    "    try:\n",
    "        async with Client(scenario.mcp_server) as client:\n",
    "            # Get available tools from the server\n",
    "            tools_result = await client.list_tools()\n",
    "\n",
    "            # Convert to OpenAI format\n",
    "            tool_schemas = []\n",
    "            for tool in tools_result:\n",
    "                tool_schema = {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description or f\"MCP tool: {tool.name}\",\n",
    "                        \"parameters\": tool.inputSchema\n",
    "                        or {\"type\": \"object\", \"properties\": {}},\n",
    "                    },\n",
    "                }\n",
    "                tool_schemas.append(tool_schema)\n",
    "\n",
    "            if debug:\n",
    "                available_tools = [\n",
    "                    tool[\"function\"][\"name\"] for tool in tool_schemas\n",
    "                ]\n",
    "                print(f\"Available MCP tools: {available_tools}\")\n",
    "\n",
    "            # Add completion tool schema\n",
    "            tool_schemas.append(\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"complete_task\",\n",
    "                        \"description\": \"Complete the task with a summary\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"summary\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Summary of accomplishments\",\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"summary\"],\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "            traj.tools = tool_schemas\n",
    "\n",
    "            # Initialize conversation\n",
    "            traj.messages_and_choices = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Please complete this task: {scenario.task_description}\",\n",
    "                },\n",
    "            ]\n",
    "\n",
    "            if debug:\n",
    "                print(traj.messages())\n",
    "\n",
    "            num_turns = 0\n",
    "            task_completed = False\n",
    "\n",
    "            # Main interaction loop\n",
    "            while num_turns < scenario.max_turns and not task_completed:\n",
    "                num_turns += 1\n",
    "\n",
    "                try:\n",
    "                    # Get LLM response\n",
    "                    async with traj.track_duration(\"llm_completion\"):\n",
    "                        openai_client = AsyncOpenAI(\n",
    "                            api_key=model.inference_api_key,\n",
    "                            base_url=model.inference_base_url,\n",
    "                        )\n",
    "\n",
    "                        response = await openai_client.chat.completions.create(\n",
    "                            model=model.inference_model_name\n",
    "                            if model.inference_model_name\n",
    "                            else model.name,\n",
    "                            messages=traj.messages(),\n",
    "                            tools=tool_schemas,\n",
    "                            max_completion_tokens=4000,\n",
    "                        )\n",
    "\n",
    "                    choice = response.choices[0]\n",
    "\n",
    "                    if debug:\n",
    "                        print(f\"Choice: {choice.message}\")\n",
    "\n",
    "                    traj.messages_and_choices.append(choice)\n",
    "\n",
    "                    # Handle tool calls\n",
    "                    if choice.message.tool_calls:\n",
    "                        for tool_call in choice.message.tool_calls:\n",
    "                            try:\n",
    "                                tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                                if tool_call.function.name == \"complete_task\":\n",
    "                                    traj.metrics[\"task_completed\"] = True\n",
    "                                    traj.log(\n",
    "                                        f\"Task completion attempted with summary: {tool_args['summary']}\"\n",
    "                                    )\n",
    "                                else:\n",
    "                                    # Call MCP tool through FastMCP client\n",
    "                                    result = await client.call_tool(\n",
    "                                        tool_call.function.name, tool_args\n",
    "                                    )\n",
    "\n",
    "                                    content_text = get_content_text(result)\n",
    "\n",
    "                                    if len(content_text) > 20000:\n",
    "                                        print(\n",
    "                                            f\"Tool call result for {tool_call.function.name} is too long: {len(content_text)}\"\n",
    "                                        )\n",
    "                                        print(f\"Args: {tool_args}\")\n",
    "                                        # print first and last 1000 characters\n",
    "                                        print(content_text[:1000])\n",
    "                                        print(content_text[-1000:])\n",
    "                                        raise Exception(\n",
    "                                            f\"Tool call result for {tool_call.function.name} is too long: {len(content_text)}\"\n",
    "                                        )\n",
    "\n",
    "                                    # Add tool response\n",
    "                                    traj.messages_and_choices.append(\n",
    "                                        {\n",
    "                                            \"role\": \"tool\",\n",
    "                                            \"tool_call_id\": tool_call.id,\n",
    "                                            \"content\": content_text,\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "                                if debug:\n",
    "                                    print(f\"Tool call result: {content_text}\")\n",
    "\n",
    "                            except Exception as e:\n",
    "                                traj.log(f\"Tool call error: {e}\")\n",
    "\n",
    "                                # Add error response\n",
    "                                traj.messages_and_choices.append(\n",
    "                                    {\n",
    "                                        \"role\": \"tool\",\n",
    "                                        \"tool_call_id\": tool_call.id,\n",
    "                                        \"content\": f\"Error: {str(e)}\",\n",
    "                                    }\n",
    "                                )\n",
    "                    else:\n",
    "                        # No tool calls, just continue conversation\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    traj.log(f\"Error in turn {num_turns}: {e}\")\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        traj.log(f\"MCP server error: {e}\")\n",
    "    if not task_completed and num_turns == scenario.max_turns:\n",
    "        traj.metrics[\"ran_out_of_turns\"] = True\n",
    "\n",
    "    traj.metrics[\"num_turns\"] = num_turns\n",
    "\n",
    "    if debug:\n",
    "        for message in traj.messages_and_choices:\n",
    "            print(\"\\n\")\n",
    "            print(message)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    return traj.finish()\n",
    "\n",
    "# =============== Training code ===============\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration from model config or use defaults\n",
    "config = getattr(model, \"config\", None)\n",
    "\n",
    "if config is None:\n",
    "    raise ValueError(\"Model config is required\")\n",
    "\n",
    "print(\n",
    "    f\"Using config: max_turns={MAX_TURNS}, rollouts_per_group={TRAINING_CONFIG['rollouts_per_group']}, groups_per_step={TRAINING_CONFIG['groups_per_step']}, num_epochs={TRAINING_CONFIG['num_epochs']}, learning_rate={TRAINING_CONFIG['learning_rate']}\"\n",
    ")\n",
    "\n",
    "await model.register(backend)\n",
    "\n",
    "train_scenarios = [\n",
    "    McpScenario(\n",
    "        task_description=scenario[\"task\"],\n",
    "        mcp_server=mcp,  # Use the FastMCP server directly\n",
    "        max_turns=MAX_TURNS,\n",
    "    )\n",
    "    for scenario in raw_train_scenarios\n",
    "]\n",
    "\n",
    "# Create dataset iterator using raw scenarios (not McpScenario objects)\n",
    "train_iterator = iterate_dataset(\n",
    "    train_scenarios,\n",
    "    groups_per_step=TRAINING_CONFIG[\"groups_per_step\"],\n",
    "    num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
    "    initial_step=await model.get_step(),  # Resume from checkpoint\n",
    ")\n",
    "\n",
    "# Main training loop using iterate_dataset\n",
    "for batch in train_iterator:\n",
    "    print(\"Gathering trajectory groups with RULER scoring...\")\n",
    "\n",
    "    # Use gather_trajectory_groups with ruler_score_group\n",
    "    groups = await art.gather_trajectory_groups(\n",
    "        (\n",
    "            art.TrajectoryGroup(\n",
    "                rollout(model, scenario, False)\n",
    "                for _ in range(TRAINING_CONFIG[\"rollouts_per_group\"])\n",
    "            )\n",
    "            for scenario in batch.items\n",
    "        ),\n",
    "        pbar_desc=f\"train gather step {batch.step}\",\n",
    "        after_each=lambda group: ruler_score_group(\n",
    "            group,\n",
    "            judge_model=RULER_MODEL,\n",
    "            debug=True,  # Show judge reasoning\n",
    "            swallow_exceptions=True,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(\"starting train\")\n",
    "    await model.train(groups, config=art.TrainConfig(learning_rate=TRAINING_CONFIG[\"learning_rate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YRO9ndqo5ky4"
   },
   "outputs": [],
   "source": [
    "# @title Test Your Model!\n",
    "\n",
    "# Generate test inputs\n",
    "print(\"Generating test inputs...\")\n",
    "val_scenarios = [\n",
    "    McpScenario(\n",
    "        task_description=scenario[\"task\"],\n",
    "        mcp_server=mcp,  # Use the FastMCP server directly\n",
    "        max_turns=MAX_TURNS,\n",
    "    )\n",
    "    for scenario in raw_val_scenarios\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ§ª Testing the trained model on {len(val_scenarios)} new inputs:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, scenario in enumerate(val_scenarios):\n",
    "    print(f\"\\nTest {i + 1}:\")\n",
    "    print(f\"Input: {scenario.task_description}\")\n",
    "\n",
    "    # Run the model\n",
    "    result_trajectory = await rollout(model, scenario)\n",
    "\n",
    "    # Extract the model's response\n",
    "    messages = result_trajectory.messages()\n",
    "    model_response = messages[-1][\"content\"] if messages else \"No response\"\n",
    "\n",
    "    print(f\"Model output: {model_response}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Testing completed!\")\n",
    "print(f\"\\nYour model '{MODEL_NAME}' has been trained to effectively use the Alphavantage MCP server.\")\n",
    "print(\"\\nTo use this model in production:\")\n",
    "print(\"1. The model checkpoint is saved in ./.art/\")\n",
    "print(\"2. You can load it using the vLLM library\")\n",
    "print(\n",
    "    \"3. Or continue training with more examples by adjusting the configuration at the top\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "utI-VYM8s5lo"
   },
   "outputs": [],
   "source": [
    "# @title Upload to Hugging Face ðŸ¤—\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "lora_model_path = (\n",
    "    f\".art/{model.project}/models/{model.name}/{await model.get_step():04d}\"\n",
    ")\n",
    "\n",
    "peft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=lora_model_path,\n",
    "    max_seq_length=16384,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "if False:  # Change to True to upload finetune\n",
    "    peft_model.push_to_hub_merged(f\"HF_ACCOUNT/{model.name}\", tokenizer, token=\"hf_...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuevYgXT-I1h"
   },
   "source": [
    "### Next Steps\n",
    "\n",
    "Congratulations! You've successfully trained a custom model for your task using only:\n",
    "- A pre-built MCP server\n",
    "- Example inputs (no outputs needed!)\n",
    "- RULER's automatic evaluation\n",
    "\n",
    "Here are some ways to improve results:\n",
    "\n",
    "1. **More diverse inputs**: Generate more varied input examples\n",
    "2. **Longer training**: Increase the number of training steps\n",
    "3. **More comparisons**: Increase `rollouts_per_group` for better RULER comparisons\n",
    "4. **MCP server refinement**: Add better tools and resources to the server\n",
    "5. **Hyperparameter tuning**: Adjust learning rate, batch size, etc.\n",
    "\n",
    "Remember: RULER learns what \"good\" means from your MCP server alone - no labeled data required!\n",
    "\n",
    "For more advanced use cases, check out the [ART documentation](https://art.openpipe.ai)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
